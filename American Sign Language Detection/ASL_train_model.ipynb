{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5c8e53d-62eb-4e82-b82e-63f08bb9449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a13b574b-2526-4147-ba02-8f2d7a7ec2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 69600 images belonging to 29 classes.\n",
      "Found 17400 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "DATA_DIR = \"asl_alphabet_train\"\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Save label map\n",
    "with open(\"label_map.json\", \"w\") as f:\n",
    "    json.dump(train_generator.class_indices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cec1816-0cbf-4ade-8bc3-7ccd3de297fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1088/1088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.2718 - loss: 2.5525"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(29, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator, validation_data=val_generator, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c87637-3c02-42eb-ab1b-2c00a756ab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"asl_cnn_model.h5\")\n",
    "# Load model and label map\n",
    "model = load_model(\"asl_cnn_model.h5\")\n",
    "with open(\"label_map.json\", \"r\") as f:\n",
    "    class_indices = json.load(f)\n",
    "    labels = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "# Load image and preprocess\n",
    "img_path = \"asl_alphabet_test/C_test.jpg\"  # change to your image\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (64, 64))\n",
    "img = img.astype(\"float\") / 255.0\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "# Predict\n",
    "pred = model.predict(img)[0]\n",
    "pred_label = labels[np.argmax(pred)]\n",
    "confidence = np.max(pred)\n",
    "\n",
    "print(f\"Prediction: {pred_label.upper()}, Confidence: {confidence*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba9d6c-ebd1-4e4d-b99e-faa160402101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# --- 2. Load your trained model ---\n",
    "model = load_model(\"asl_cnn_model.h5\")  # ✅ This should already exist from earlier\n",
    "\n",
    "# --- 3. Set the image size and class labels ---\n",
    "IMG_SIZE = 64  # or whatever your model was trained with\n",
    "class_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J',\n",
    "    'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T',\n",
    "    'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "    'DELETE', 'NOTHING', 'SPACE']  # all 29 classes\n",
    "\n",
    "# --- 4. (Optional) test with static image ---\n",
    "# Code to test a single image, if you want to try before webcam\n",
    "\n",
    "# --- 5. ADD THIS BLOCK AT THE END — Real-Time Webcam Detection ---\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(\"Starting real-time ASL detection... Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize the frame for prediction\n",
    "    roi = cv2.resize(frame, (64, 64))\n",
    "    roi = roi.astype(\"float32\") / 255.0\n",
    "    roi = np.expand_dims(roi, axis=0)\n",
    "\n",
    "    # Predict the sign\n",
    "    prediction = model.predict(roi)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    print(\"Predicted index:\", predicted_class)\n",
    "    print(\"Total labels:\", len(class_names))\n",
    "    label = class_names[predicted_class]\n",
    "\n",
    "    # Show result on video\n",
    "    cv2.putText(frame, f'Predicted: {label}', (10, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"ASL Real-Time Detection\", frame)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee26ed05-1894-4266-8abf-4d962ee1ee02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
